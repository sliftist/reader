todonext


8) Test on phone

9) ElevenLabs model dropdown selector

10) Local model runner
    - Via providing local port?
    - We'll have to make sure this works even if we are running it on a real site
    - Eleven labs is too expensive! Over a dollar per 1000 tokens!

10.1) Allow a model for speaking, and a model for narration
    - Also, better speaking splitting, as right now it's not great...



7) Allow editting of segments directly

8) Cache segments (at least in memory), so if there is an edit, we don't regenerate ALL of them
    - But, ONLY if there is an edit. If they just click regenerate, without an edit, make new audio.

8.1) Regenerate audio button PER segment, so we can vary performances.
    - We need audio to be associated with the segment, instead of just flat as we are doing now

9) Assign speaker persistent hues, so we can try to make sure they vary more


10) Better speaker segmentation, to not lose narration as much?
    - Maybe use an inline format, basically parsing speakers ourselves, and just getting the AI to inject names to help us
        ALTHOUGH, maybe some text, such as "he said", is not needed, as... if he literally says it, then... that's completely redundant.

8) Tell the AI to add elevenlabs syntax
    "Give me one second to think about it." <break time="1.0s" /> "Yes, that would work."
    <phoneme alphabet="ipa" ph="ˈæktʃuəli">actually</phoneme>
    - ALSO, encode breaks between speakers, so we can have them cut each other off, etc
    - ALSO, reload audio into memory when playing it, so there isn't a delay to load the audio from disk, decode it, etc

6) Support saving/restoring data from google drive
    - And maybe auto saving it every... day? Or week?

9) Voice caching?
    - Mostly in case we edit a very large paragraph slightly? Although... how many times will we do that...

10) Custom voices
    - Do voices we add in the site show up in our voices?
    - Try to add some library voices.
    - Try to add our voice, or... other voices.

10) Use eslint-plugin-no-disposable-without-using, somehow?

Advanced Features
    Two column display
        - Outline => output model, instead of chat
        - Two colums of textboxes on each size, which grow to the text size
            - Two new lines make a new textbox
        - The focused textbox is always in the center, with the corresponding output beside it (in the other column)
            - The other boxes are rendered tightly packed
        - Page up / page down move between textboxes?



    Variable support
        - Mostly for common prompt templates

    Variables work in series, but also search other books (in which case they are just what the book exports, which is everything, but default)
        - Exports have timestamp of the first message that set the latest value
        - If it's is another book a button to copy from the other book is shown (for each other unique version, showing the FIRST book to have that version)
            - Also an option to copy TO all the other versions of it, mostly to reduce all of the duplicate buttons
            - Maybe a button to explicitly mark it as "no-import", to make the UI go away, as it might be annoying

    Variable parameters

        @detailed_person(Ralph)
        @detailed_person(@protagonist)

        <add detail to $0>@detailed_person
    We could also support variables with parameters, for the purpose of choosing the context we query

    Default variables
        @prevParagraph
        @nextParagraph

    THIRD column, for chaining prompts, so we don't have to write the wrapping code each time
        - Copies from previous when we new paragraph is created
            - Detects identical and partial opacities, so we can ignore it most of the time
        - Collapsable?

        @history_context
        @detailed_action_instructions
        @weather_and_temperature_reminder
        @no_pathetic_fallacy
        @prevParagraphContext
        @futureParagraphContext
        @paragraph
        @subject_reminder

        AND, prevParagraph/nextParagraph will reference the NON context template parts, so they can be cleaner


    Nested prompts, evaluated first
        <{get the subject from @paragraph, @singlewordoutput}>@subject
            - As in, the text inside the brace is evaluated, with the variables, etc, and then is placed there, which sets the subject

        NOTE: If you just want to give directions, that can be done inline, such as *AI, please add description of the room here*, although that is probably best put in a variable, so that can be reused.

    Better context
        - Dynamically determine embedding query with AI
        - Search other books, etc
        - Use AI to filter context future
        - Tab to see context for any prompt

    Summarization with further columns
        - Allow adding more columns
            - I guess only 1 or 2 summarization columns can be visible. Anymore and it just gets ridiculous
        - Apply nested summarization code
            - Automatically keep it update it for > 2 paragraphs old
        - This allows us to navigate via summaries at any level
        - Allow referencing this in the context?

    Specific extraction for context
        - Places, characters, etc
